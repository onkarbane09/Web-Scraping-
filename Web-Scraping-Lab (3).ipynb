{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hands-on Lab : Web Scraping**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30 to 45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract information from a given web site \n",
    "* Write the scraped data into a csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information from the given web site\n",
    "You will extract the data from the below web site: <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this url contains the data you need to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data you need to scrape is the **name of the programming language** and **average annual salary**.<br> It is a good idea to open the url in your web broswer and study the contents of the web page before you start to scrape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the webpage at the url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage downloaded successfully!\n",
      "\n",
      "Webpage content saved in downloaded_webpage.html\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "\n",
    "import requests\n",
    "\n",
    "# URL to download\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "\n",
    "# Step 1: Send a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Webpage downloaded successfully!\\n\")\n",
    "    \n",
    "    # Step 2: Save the webpage content to a text file\n",
    "    file_path = \"downloaded_webpage.html\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(response.text)\n",
    "    \n",
    "    print(f\"Webpage content saved in {file_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to download the webpage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a soup object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage downloaded successfully!\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   Salary survey results of programming languages\n",
      "  </title>\n",
      "  <style>\n",
      "   table, th, td {\n",
      "  border: 1px solid black;\n",
      "}\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <hr/>\n",
      "  <h2>\n",
      "   Popular Programming Languages\n",
      "  </h2>\n",
      "  <hr/>\n",
      "  <p>\n",
      "   Finding out which is the best language is a tough task. A programming language is created to solve a specific problem. A language which is good for task A may not be able to properly handle task B. Comparing programming language \n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "\n",
    "# Step 1: Download the webpage content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Webpage downloaded successfully!\\n\")\n",
    "\n",
    "    # Step 2: Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")  # Parsing HTML\n",
    "\n",
    "    # Print the first 500 characters of the webpage content (optional)\n",
    "    print(soup.prettify()[:500])\n",
    "\n",
    "else:\n",
    "    print(\"Failed to download the webpage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the `Language name` and `annual average salary`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage downloaded successfully!\n",
      "\n",
      "Extracted Data:\n",
      "-----------------------------\n",
      "1 ---> Python\n",
      "2 ---> Java\n",
      "3 ---> R\n",
      "4 ---> Javascript\n",
      "5 ---> Swift\n",
      "6 ---> C++\n",
      "7 ---> C#\n",
      "8 ---> PHP\n",
      "9 ---> SQL\n",
      "10 ---> Go\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68/4278862585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Step 5: Save the extracted data into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Programming Language\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Average Annual Salary\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Step 6: Save the DataFrame to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "\n",
    "# URL containing the data to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "\n",
    "# Step 1: Download the webpage content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Webpage downloaded successfully!\\n\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Create a BeautifulSoup object to parse HTML\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Step 3: Find the table in the webpage\n",
    "table = soup.find('table')  # Tables are represented with the <table> tag\n",
    "\n",
    "# Step 4: Extract table data (Programming Language and Salary)\n",
    "data = []\n",
    "print(\"Extracted Data:\\n-----------------------------\")\n",
    "for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "    cols = row.find_all('td')\n",
    "    language = cols[0].getText().strip()  # First column - Programming Language\n",
    "    salary = cols[1].getText().strip()  # Second column - Average Annual Salary\n",
    "    data.append([language, salary])\n",
    "    print(f\"{language} ---> {salary}\")  # Print extracted data\n",
    "\n",
    "# Step 5: Save the extracted data into a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Programming Language\", \"Average Annual Salary\"])\n",
    "\n",
    "# Step 6: Save the DataFrame to a CSV file\n",
    "df.to_csv(\"programming_languages_salaries.csv\", index=False)\n",
    "\n",
    "print(\"\\nScraped data saved successfully in 'programming_languages_salaries.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scrapped data into a file named *popular-languages.csv*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage downloaded successfully!\n",
      "\n",
      "Extracted Data:\n",
      "-----------------------------\n",
      "1 ---> Python\n",
      "2 ---> Java\n",
      "3 ---> R\n",
      "4 ---> Javascript\n",
      "5 ---> Swift\n",
      "6 ---> C++\n",
      "7 ---> C#\n",
      "8 ---> PHP\n",
      "9 ---> SQL\n",
      "10 ---> Go\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68/4005323552.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Step 5: Save the extracted data into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Programming Language\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Average Annual Salary\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Step 6: Save the DataFrame to a CSV file named 'popular-languages.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Webpage downloaded successfully!\\n\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Create a BeautifulSoup object to parse HTML\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Step 3: Find the table in the webpage\n",
    "table = soup.find('table')  # Tables are represented with the <table> tag\n",
    "\n",
    "# Step 4: Extract table data (Programming Language and Salary)\n",
    "data = []\n",
    "print(\"Extracted Data:\\n-----------------------------\")\n",
    "for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "    cols = row.find_all('td')\n",
    "    language = cols[0].getText().strip()  # First column - Programming Language\n",
    "    salary = cols[1].getText().strip()  # Second column - Average Annual Salary\n",
    "    data.append([language, salary])\n",
    "    print(f\"{language} ---> {salary}\")  # Print extracted data\n",
    "\n",
    "# Step 5: Save the extracted data into a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Programming Language\", \"Average Annual Salary\"])\n",
    "\n",
    "# Step 6: Save the DataFrame to a CSV file named 'popular-languages.csv'\n",
    "csv_filename = \"popular-languages.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"\\nScraped data saved successfully in '{csv_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-10-17  | 0.1  | Ramesh Sannareddy  |  Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright &copy; 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
